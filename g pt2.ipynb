{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
      ],
      "metadata": {
        "id": "sD17ZCy3OO7h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
      ],
      "metadata": {
        "id": "rNa02xwJORfv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Kullanılan cihaz:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDBmUxeVOTeU",
        "outputId": "4805dd3e-a1b5-4e6c-ff00-5ef27fa8b978"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kullanılan cihaz: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(\"Toplam örnek sayısı:\", len(data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKKLoTerOUws",
        "outputId": "45834f56-cae2-456d-bd54-3973e5376fc1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toplam örnek sayısı: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = sorted(list(set(item[\"davaTuru\"].split(\",\")[0].strip() for item in data)))\n",
        "\n",
        "label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "id2label = {idx: label for label, idx in label2id.items()}\n",
        "\n",
        "print(\"Label mapping:\")\n",
        "print(label2id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvIPe5X7OeEu",
        "outputId": "28119b2d-ce48-4175-b0dc-24b89867b193"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label mapping:\n",
            "{'Borç': 0, 'Ceza': 1, 'Ceza (Güvenilirlik: Ceza: %72)': 2, 'Icra iflas': 3, 'Ihale (Güvenilirlik: Ihale: %22)': 4, 'Iş': 5, 'Mahkeme uyuşmazlık': 6, 'Miras': 7, 'Mülkiyet': 8, 'Trafik': 9, 'Uyuşturucu': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(\n",
        "    data,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(train_data))\n",
        "print(\"Test :\", len(test_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGMnZaT-Og6L",
        "outputId": "5d0d31e8-d55f-4164-c1c8-3891886c7525"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 80\n",
            "Test : 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3szN0ip6Oi_D",
        "outputId": "3c1a2854-099a-4e8f-c948-a2da71eda687"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CaseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        text = item[\"content\"]\n",
        "        label_text = item[\"davaTuru\"].split(\",\")[0].strip()\n",
        "        label = label2id[label_text]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "VBO05j3vOkjj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CaseDataset(train_data, tokenizer)\n",
        "test_dataset  = CaseDataset(test_data, tokenizer)\n"
      ],
      "metadata": {
        "id": "E_wMjms7OlTu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"dbmdz/bert-base-turkish-cased\",\n",
        "    num_labels=len(label2id),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yhdCRsXOnYB",
        "outputId": "a1838c8a-d0fb-4044-bf8e-e443cc003b24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=\"weighted\"\n",
        "    )\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }\n"
      ],
      "metadata": {
        "id": "dIzq1m2mOpl7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n"
      ],
      "metadata": {
        "id": "t1zRwveCQA1D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "9tHxBzbHOri5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxM9PYxXOtrF",
        "outputId": "9acc4153-5e0d-4c2b-b921-d9aa122df512"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2147312783.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "Xleu3iZIOwdd",
        "outputId": "1c34b365-ee4c-4a45-baa2-838d9fc9baa9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:17, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.445100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.429000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.073200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.786600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.438900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.881500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.677100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.461800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.415200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.585700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.412900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.206900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=120, training_loss=1.7344920794169107, metrics={'train_runtime': 18.5108, 'train_samples_per_second': 12.965, 'train_steps_per_second': 6.483, 'total_flos': 63151756001280.0, 'train_loss': 1.7344920794169107, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.evaluate()\n",
        "print(\"Test Metrikleri:\")\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "hsQCMuzkOyZq",
        "outputId": "2933eb39-e64f-4032-8bae-087d7faeadb3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrikleri:\n",
            "eval_loss: 1.5059\n",
            "eval_accuracy: 0.6000\n",
            "eval_precision: 0.6167\n",
            "eval_recall: 0.6000\n",
            "eval_f1: 0.6022\n",
            "eval_runtime: 0.5385\n",
            "eval_samples_per_second: 37.1410\n",
            "eval_steps_per_second: 18.5700\n",
            "epoch: 3.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "for i in range(min(3, len(test_data))):\n",
        "    item = test_data[i]\n",
        "    text = item[\"content\"]\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        pred_id = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"METİN:\", text[:300], \"...\")\n",
        "    print(\"GERÇEK:\", item[\"davaTuru\"])\n",
        "    print(\"TAHMİN:\", id2label[pred_id])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W3KZP6JO0ej",
        "outputId": "f58ff6a2-a286-4e95-ef54-92a7cedc3def"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "METİN: 4. Ceza Dairesi 2020/27481 E. , 2023/49 K. Asliye Ceza Mahkemesi SUÇLAR : Hakaret, tehdit Sanık hakkında kurulan hükümlerin; karar tarihi itibarıyla 6723 sayılı Kanun'un 33 üncü maddesiyle değişik 5320 sayılı Kanun'un 8 inci maddesi gereği yürürlükte bulunan 1412 sayılı Ceza Muhakemeleri Usulü Kanun ...\n",
            "GERÇEK: Ceza, Ceza (Güvenilirlik: Ceza: %100 | Ceza: %100)\n",
            "TAHMİN: Ceza\n",
            "============================================================\n",
            "METİN: 5. Hukuk Dairesi 2022/14205 E. , 2023/1 K. Aile Mahkemesi I. YARGI YERİ BELİRLENMESİNE KONU KARARLAR A. Bursa 1. İcra Ceza Mahkemesinin 14. 06. 2022 Tarihli ve 2022/76 Esas, 2022/226 Karar Sayılı Kararı Çocuk teslimi emrine mualefet etme suçundan cezalandırılması istemli şikâyeti inceleme görev ve y ...\n",
            "GERÇEK: Ceza, Borç (Güvenilirlik: Ceza: %95 | Borç: %68)\n",
            "TAHMİN: Mahkeme uyuşmazlık\n",
            "============================================================\n",
            "METİN: 5. Hukuk Dairesi 2022/14161 E. , 2023/3 K. Asliye Hukuk Mahkemesi (Tüketici Mahkemesi Sıfatıyla) I. YARGI YERİ BELİRLENMESİNE KONU KARARLAR A. İstanbul Anadolu 3. Tüketici Mahkemesinin 13. 11. 2018 Tarihli ve 2017/438 Esas, 2018/947 Karar Sayılı Kararı Davanın kısmen kabul kısmen reddi ile taraflar  ...\n",
            "GERÇEK: Mülkiyet, Mahkeme uyuşmazlık (Güvenilirlik: Mülkiyet: %100 | Mahkeme uyuşmazlık: %68)\n",
            "TAHMİN: Mahkeme uyuşmazlık\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tokens(dataset):\n",
        "    total = 0\n",
        "    for item in dataset:\n",
        "        tokens = tokenizer.encode(\n",
        "            item[\"content\"],\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "        total += len(tokens)\n",
        "    return total\n",
        "\n",
        "train_tokens = count_tokens(train_data)\n",
        "test_tokens  = count_tokens(test_data)\n",
        "\n",
        "print(\"Toplam Train Token:\", train_tokens)\n",
        "print(\"Toplam Test  Token:\", test_tokens)\n",
        "print(\"GENEL TOPLAM:\", train_tokens + test_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71L9g8qZO2OM",
        "outputId": "e4e9ba7b-28d1-4fe1-f28e-f1a1f0eb31cb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toplam Train Token: 30595\n",
            "Toplam Test  Token: 7680\n",
            "GENEL TOPLAM: 38275\n"
          ]
        }
      ]
    }
  ]
}